{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\i327950\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:843: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, nltk\n",
    "import gensim\n",
    "import codecs\n",
    "from sner import Ner\n",
    "import spacy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.internals import find_jars_within_path\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import spacy\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_train = open('traininig_dataset (1) (1).txt', 'r+')\n",
    "f_test = open('validation_dataset (1) (1).txt', 'r+')\n",
    "\n",
    "train = pd.DataFrame(f_train.readlines(), columns = ['Question'])\n",
    "test = pd.DataFrame(f_test.readlines(), columns = ['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['QType'] = train.Question.apply(lambda x: x.split(' ', 1)[0])\n",
    "train['Question'] = train.Question.apply(lambda x: x.split(' ', 1)[1])\n",
    "train['QType-Coarse'] = train.QType.apply(lambda x: x.split(':')[0])\n",
    "train['QType-Fine'] = train.QType.apply(lambda x: x.split(':')[1])\n",
    "test['QType'] = test.Question.apply(lambda x: x.split(' ', 1)[0])\n",
    "test['Question'] = test.Question.apply(lambda x: x.split(' ', 1)[1])\n",
    "test['QType-Coarse'] = test.QType.apply(lambda x: x.split(':')[0])\n",
    "test['QType-Fine'] = test.QType.apply(lambda x: x.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>QType</th>\n",
       "      <th>QType-Coarse</th>\n",
       "      <th>QType-Fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What films featured the character Popeye Doyle...</td>\n",
       "      <td>ENTY:cremat</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>cremat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>ENTY:animal</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the full form of .com ?\\n</td>\n",
       "      <td>ABBR:exp</td>\n",
       "      <td>ABBR</td>\n",
       "      <td>exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question        QType  \\\n",
       "0  How did serfdom develop in and then leave Russ...  DESC:manner   \n",
       "1  What films featured the character Popeye Doyle...  ENTY:cremat   \n",
       "2  How can I find a list of celebrities ' real na...  DESC:manner   \n",
       "3  What fowl grabs the spotlight after the Chines...  ENTY:animal   \n",
       "4                  What is the full form of .com ?\\n     ABBR:exp   \n",
       "\n",
       "  QType-Coarse QType-Fine  \n",
       "0         DESC     manner  \n",
       "1         ENTY     cremat  \n",
       "2         DESC     manner  \n",
       "3         ENTY     animal  \n",
       "4         ABBR        exp  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>QType</th>\n",
       "      <th>QType-Coarse</th>\n",
       "      <th>QType-Fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>500</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>How cold should a refrigerator be ?\\n</td>\n",
       "      <td>DESC:def</td>\n",
       "      <td>DESC</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>138</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Question     QType QType-Coarse  \\\n",
       "count                                     500       500          500   \n",
       "unique                                    500        42            6   \n",
       "top     How cold should a refrigerator be ?\\n  DESC:def         DESC   \n",
       "freq                                        1       123          138   \n",
       "\n",
       "       QType-Fine  \n",
       "count         500  \n",
       "unique         39  \n",
       "top           def  \n",
       "freq          123  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>QType</th>\n",
       "      <th>QType-Coarse</th>\n",
       "      <th>QType-Fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How far is it from Denver to Aspen ?\\n</td>\n",
       "      <td>NUM:dist</td>\n",
       "      <td>NUM</td>\n",
       "      <td>dist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What county is Modesto , California in ?\\n</td>\n",
       "      <td>LOC:city</td>\n",
       "      <td>LOC</td>\n",
       "      <td>city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was Galileo ?\\n</td>\n",
       "      <td>HUM:desc</td>\n",
       "      <td>HUM</td>\n",
       "      <td>desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is an atom ?\\n</td>\n",
       "      <td>DESC:def</td>\n",
       "      <td>DESC</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When did Hawaii become a state ?\\n</td>\n",
       "      <td>NUM:date</td>\n",
       "      <td>NUM</td>\n",
       "      <td>date</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Question     QType QType-Coarse  \\\n",
       "0      How far is it from Denver to Aspen ?\\n  NUM:dist          NUM   \n",
       "1  What county is Modesto , California in ?\\n  LOC:city          LOC   \n",
       "2                         Who was Galileo ?\\n  HUM:desc          HUM   \n",
       "3                         What is an atom ?\\n  DESC:def         DESC   \n",
       "4          When did Hawaii become a state ?\\n  NUM:date          NUM   \n",
       "\n",
       "  QType-Fine  \n",
       "0       dist  \n",
       "1       city  \n",
       "2       desc  \n",
       "3        def  \n",
       "4       date  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>QType</th>\n",
       "      <th>QType-Coarse</th>\n",
       "      <th>QType-Fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5952</td>\n",
       "      <td>5952</td>\n",
       "      <td>5952</td>\n",
       "      <td>5952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5871</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>How deep is a fathom ?\\n</td>\n",
       "      <td>HUM:ind</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>1017</td>\n",
       "      <td>1344</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Question    QType QType-Coarse QType-Fine\n",
       "count                       5952     5952         5952       5952\n",
       "unique                      5871       50            6         47\n",
       "top     How deep is a fathom ?\\n  HUM:ind         ENTY        ind\n",
       "freq                           3     1017         1344       1017"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.append(test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be observed, the train set consists of some duplicate question (81 to be exact). <br>\n",
    "The number of unique Coarse:Fine classes is 50 whereas entries corresponding to 42 are present in the test set. <br>\n",
    "The number of fine classes overall is 47 whereas entries corresponding to 39 are present in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.Series(train.QType.tolist() + test.QType.tolist()).values)\n",
    "train['QType'] = le.transform(train.QType.values)\n",
    "test['QType'] = le.transform(test.QType.values)\n",
    "le2 = LabelEncoder()\n",
    "le2.fit(pd.Series(train['QType-Coarse'].tolist() + test['QType-Coarse'].tolist()).values)\n",
    "train['QType-Coarse'] = le2.transform(train['QType-Coarse'].values)\n",
    "test['QType-Coarse'] = le2.transform(test['QType-Coarse'].values)\n",
    "le3 = LabelEncoder()\n",
    "le3.fit(pd.Series(train['QType-Fine'].tolist() + test['QType-Fine'].tolist()).values)\n",
    "train['QType-Fine'] = le3.transform(train['QType-Fine'].values)\n",
    "test['QType-Fine'] = le3.transform(test['QType-Fine'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>QType</th>\n",
       "      <th>QType-Coarse</th>\n",
       "      <th>QType-Fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What films featured the character Popeye Doyle...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the full form of .com ?\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  QType  QType-Coarse  \\\n",
       "0  How did serfdom develop in and then leave Russ...      4             1   \n",
       "1  What films featured the character Popeye Doyle...      9             2   \n",
       "2  How can I find a list of celebrities ' real na...      4             1   \n",
       "3  What fowl grabs the spotlight after the Chines...      6             2   \n",
       "4                  What is the full form of .com ?\\n      1             0   \n",
       "\n",
       "   QType-Fine  \n",
       "0          23  \n",
       "1           8  \n",
       "2          23  \n",
       "3           1  \n",
       "4          16  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_corpus = pd.Series(train.Question.tolist() + test.Question.tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining Dotwords.<br>\n",
    "Also, performing text cleaning and pre-processing in the next two blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\I327950\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\I327950\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "dot_words = []\n",
    "for row in all_corpus:\n",
    "    for word in row.split():\n",
    "        if '.' in word and len(word)>2:\n",
    "            dot_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_clean(corpus, keep_list):\n",
    "    '''\n",
    "    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
    "    \n",
    "    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n",
    "            even after the cleaning process\n",
    "    \n",
    "    Output : Returns the cleaned text corpus\n",
    "    \n",
    "    '''\n",
    "    cleaned_corpus = pd.Series()\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
    "    return cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(corpus, keep_list, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
    "    \n",
    "    '''\n",
    "    Purpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\n",
    "    \n",
    "    Input : \n",
    "    'corpus' - Text corpus on which pre-processing tasks will be performed\n",
    "    'keep_list' - List of words to be retained during cleaning process\n",
    "    'cleaning', 'stemming', 'lemmatization', 'remove_stopwords' - Boolean variables indicating whether a particular task should \n",
    "                                                                  be performed or not\n",
    "    'stem_type' - Choose between Porter stemmer or Snowball(Porter2) stemmer. Default is \"None\", which corresponds to Porter\n",
    "                  Stemmer. 'snowball' corresponds to Snowball Stemmer\n",
    "    \n",
    "    Note : Either stemming or lemmatization should be used. There's no benefit of using both of them together\n",
    "    \n",
    "    Output : Returns the processed text corpus\n",
    "    \n",
    "    '''\n",
    "    if cleaning == True:\n",
    "        corpus = text_clean(corpus, keep_list)\n",
    "    \n",
    "    if remove_stopwords == True:\n",
    "        wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
    "        stop = set(stopwords.words('english'))\n",
    "        for word in wh_words:\n",
    "            stop.remove(word)\n",
    "        corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
    "    else :\n",
    "        corpus = [[x for x in x.split()] for x in corpus]\n",
    "    \n",
    "    if lemmatization == True:\n",
    "        lem = WordNetLemmatizer()\n",
    "        corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
    "    \n",
    "    if stemming == True:\n",
    "        if stem_type == 'snowball':\n",
    "            stemmer = SnowballStemmer(language = 'english')\n",
    "            corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "        else :\n",
    "            stemmer = PorterStemmer()\n",
    "            corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    \n",
    "    corpus = [' '.join(x) for x in corpus]\n",
    "        \n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_dot_words = ['U.S.', 'St.', 'Mr.', 'Mrs.', 'D.C.']\n",
    "all_corpus = preprocess(all_corpus, keep_list = common_dot_words, remove_stopwords = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the English model for Spacy.<br>\n",
    "NLTK version for the same performs too slowly, hence opting for Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating list of Named Entitites, Lemmas, POS Tags, Syntactic Dependency Relation and Orthographic Features using shape.<br>\n",
    "Later, these would be used as features for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ner = []\n",
    "all_lemma = []\n",
    "all_tag = []\n",
    "all_dep = []\n",
    "all_shape = []\n",
    "for row in all_corpus:\n",
    "    doc = nlp(row)\n",
    "    present_lemma = []\n",
    "    present_tag = []\n",
    "    present_dep = []\n",
    "    present_shape = []\n",
    "    present_ner = []\n",
    "    #print(row)\n",
    "    for token in doc:\n",
    "        present_lemma.append(token.lemma_)\n",
    "        present_tag.append(token.tag_)\n",
    "        #print(present_tag)\n",
    "        present_dep.append(token.dep_)\n",
    "        present_shape.append(token.shape_)\n",
    "    all_lemma.append(\" \".join(present_lemma))\n",
    "    all_tag.append(\" \".join(present_tag))\n",
    "    all_dep.append(\" \".join(present_dep))\n",
    "    all_shape.append(\" \".join(present_shape))\n",
    "    for ent in doc.ents:\n",
    "        present_ner.append(ent.label_)\n",
    "    all_ner.append(\" \".join(present_ner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the attributes obtained above into vectors using CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vec_ner = CountVectorizer(ngram_range=(1, 2)).fit(all_ner)\n",
    "ner_ft = count_vec_ner.transform(all_ner)\n",
    "count_vec_lemma = CountVectorizer(ngram_range=(1, 2)).fit(all_lemma)\n",
    "lemma_ft = count_vec_lemma.transform(all_lemma)\n",
    "count_vec_tag = CountVectorizer(ngram_range=(1, 2)).fit(all_tag)\n",
    "tag_ft = count_vec_tag.transform(all_tag)\n",
    "count_vec_dep = CountVectorizer(ngram_range=(1, 2)).fit(all_dep)\n",
    "dep_ft = count_vec_dep.transform(all_dep)\n",
    "count_vec_shape = CountVectorizer(ngram_range=(1, 2)).fit(all_shape)\n",
    "shape_ft = count_vec_shape.transform(all_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the features obtained into 1 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_all_ft = hstack([ner_ft, lemma_ft, tag_ft, dep_ft, shape_ft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5952x29210 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 184291 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from COOrdinate format to Compressed Sparse Row format for easier mathematical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5952x29210 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 184291 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all_ft_csr = x_all_ft.tocsr()\n",
    "x_all_ft_csr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting obtained matrix to original test and train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5452x29210 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 172919 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all_ft_train = x_all_ft_csr[0:train.shape[0],:]\n",
    "x_all_ft_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x29210 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11372 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all_ft_test = x_all_ft_csr[train.shape[0]:,:]\n",
    "x_all_ft_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature study over the years has shown Linear SVM performs best in this Use Case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Modelling for Coarse Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_all_ft_train, train['QType-Coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_all_ft_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 1, 5, 5, 3, 1, 1, 1, 4, 1, 5, 3, 5, 5, 4, 3, 1, 5, 3, 1, 4,\n",
       "       1, 1, 3, 1, 2, 4, 1, 5, 4, 1, 5, 5, 5, 4, 5, 5, 5, 2, 1, 1, 1, 3, 2,\n",
       "       5, 1, 5, 3, 1, 3, 3, 1, 1, 1, 5, 4, 4, 5, 4, 3, 4, 2, 4, 3, 2, 1, 5,\n",
       "       4, 5, 5, 4, 3, 4, 1, 2, 5, 5, 3, 1, 5, 3, 5, 5, 1, 1, 3, 1, 4, 2, 1,\n",
       "       5, 5, 4, 4, 5, 1, 1, 3, 1, 3, 1, 3, 4, 1, 5, 2, 5, 4, 2, 1, 4, 2, 4,\n",
       "       3, 5, 1, 5, 4, 5, 2, 1, 3, 1, 3, 1, 5, 1, 5, 5, 3, 1, 1, 1, 1, 4, 3,\n",
       "       3, 1, 1, 2, 4, 2, 1, 2, 3, 2, 1, 1, 2, 3, 1, 5, 3, 4, 4, 1, 2, 4, 1,\n",
       "       1, 5, 4, 2, 2, 5, 1, 4, 3, 5, 5, 5, 1, 4, 4, 4, 5, 2, 5, 4, 1, 4, 1,\n",
       "       2, 3, 3, 1, 4, 1, 1, 4, 5, 5, 1, 4, 2, 3, 2, 2, 3, 4, 3, 2, 1, 4, 3,\n",
       "       5, 1, 1, 5, 5, 1, 4, 1, 2, 1, 2, 5, 1, 1, 5, 1, 1, 4, 2, 5, 1, 4, 3,\n",
       "       5, 3, 1, 5, 2, 1, 4, 1, 4, 5, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 3, 1, 2,\n",
       "       2, 1, 4, 4, 2, 1, 4, 3, 3, 5, 2, 5, 1, 1, 4, 5, 1, 2, 3, 1, 3, 1, 2,\n",
       "       1, 5, 0, 2, 4, 3, 0, 1, 4, 1, 1, 1, 1, 1, 4, 2, 5, 2, 1, 1, 2, 5, 1,\n",
       "       2, 0, 5, 1, 5, 5, 4, 3, 4, 3, 5, 4, 4, 5, 1, 4, 1, 3, 4, 2, 4, 1, 5,\n",
       "       1, 2, 5, 1, 1, 5, 5, 1, 1, 5, 2, 2, 1, 4, 1, 2, 1, 5, 5, 2, 5, 3, 5,\n",
       "       3, 3, 1, 5, 1, 5, 4, 4, 2, 1, 3, 1, 1, 1, 2, 1, 1, 3, 5, 1, 2, 2, 2,\n",
       "       1, 4, 1, 2, 1, 2, 3, 5, 4, 1, 0, 1, 3, 3, 2, 3, 5, 5, 1, 3, 1, 1, 3,\n",
       "       1, 2, 5, 1, 1, 1, 5, 5, 4, 1, 1, 5, 0, 5, 4, 1, 4, 5, 1, 3, 1, 4, 0,\n",
       "       4, 1, 1, 1, 3, 3, 5, 1, 3, 1, 4, 2, 1, 4, 1, 3, 1, 2, 4, 3, 1, 1, 1,\n",
       "       5, 0, 2, 3, 1, 4, 3, 3, 2, 4, 3, 5, 2, 2, 2, 2, 5, 1, 5, 2, 4, 1, 1,\n",
       "       1, 2, 1, 1, 4, 2, 1, 3, 1, 1, 1, 1, 2, 5, 2, 2, 1, 5, 2, 4, 3, 2, 2,\n",
       "       1, 4, 1, 4, 5, 2, 2, 1, 1, 2, 5, 5, 3, 2, 5, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['QType-Coarse'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glad to announce, Feature Engineering has enabled us to achieve an Accuracy of 87.8% on the validation set.<br>\n",
    "The obtained accuracy is way higher than the 73% accuracy obtained without feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will obtain accuracies for Coarse:Fine combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_all_ft_train, train['QType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_all_ft_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80400000000000005"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['QType'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Woah, up to 80.4% accuracy from 68% obtained earlier when modelled without Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would evaluate our performance for the fine classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_all_ft_train, train['QType-Fine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_all_ft_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80800000000000005"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['QType-Fine'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, We haved achieved an accuracy of 80.8% over the Fine Classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We achieved great accuracies using Feature Engineering as compared to accuracies obtained without feature engineering.\n",
    "(The notebook for models obtained without feature engineering is not being shared and one can try implementing it easily).\n",
    "\n",
    "Experimenting with informer hypernyms can further help in accuracy improvement as suggested in https://nlp.stanford.edu/courses/cs224n/2010/reports/olalerew.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
